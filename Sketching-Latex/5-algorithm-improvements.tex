\section{Algorithm Improvements and Stability Analysis}

\subsection{Issue Identification: Component Mixing and Basis Mismatch}
During the evaluation of the JESPRIT algorithm, a significant issue was observed where the estimated rates ($\bm{\lambda}$) exhibited "mass stealing" between components. For example, in a scenario with true rates of 100 and 100, the algorithm would consistently estimate approximately 75 and 126. This systematic error persisted even with a large number of samples, indicating a bias rather than variance.

The root cause was identified in the interaction between the subspace estimation and the Joint Diagonalization step. Theoretical derivations of JESPRIT often assume a single global signal subspace. However, the practical implementation estimates the signal subspace $\bm{U}_s^{(l)}$ **independently** for each direction $l$ using the specific data slice corresponding to that direction.

Because of finite sample noise and the random nature of the projections, these estimated subspaces $\bm{U}_s^{(l)}$ differ **substantially** across directions. Consequently, the Rotational Invariance Matrices $\bm{\Psi}_l$ are defined in **different bases** (different coordinate systems).

This creates two fundamental problems for the standard joint diagonalization approach:
\begin{enumerate}
    \item \textbf{Basis Mismatch:} Since the matrices do not share a common basis (eigenvectors), they are not simultaneously diagonalizable. Commutator checks confirmed that $\|\bm{\Psi}_i \bm{\Psi}_j - \bm{\Psi}_j \bm{\Psi}_i\| \gg 0$.
    \item \textbf{Non-Unitary Diagonalizer:} Even if they shared a basis, the true diagonalizing transformation is not necessarily unitary in the general case, whereas standard algorithms like Jacobi rotations are constrained to unitary matrices.
\end{enumerate}

The combination of these factors means that forcing a single unitary matrix to diagonalize all $\bm{\Psi}_l$ results in a compromise solution that "mixes" the components, leading to the observed "mass stealing" bias.

\subsection{Proposed Solution: Brute-Force Eigenvalue Matching}
To resolve this, we replaced the joint diagonalization approach with a Brute-Force Eigenvalue Matching strategy. This method acknowledges that while the eigenvectors may differ across directions, the eigenvalues (which contain the frequency information) are intrinsic to the underlying components.

The improved algorithm proceeds as follows:

\begin{enumerate}
    \item \textbf{Independent Diagonalization:} Instead of attempting to find a common basis, we compute the eigendecomposition of each $\bm{\Psi}_l$ independently:
    \[
    \bm{\Psi}_l = \bm{V}_l \bm{D}_l \bm{V}_l^{-1}
    \]
    where $\bm{D}_l$ is a diagonal matrix containing the eigenvalues $\mu_{l,k} = \exp(j \delta \bm{u}_l^\top \bm{\omega}_k)$. This avoids the error introduced by enforcing a common basis.

    \item \textbf{Basis Selection:} We select a subset of $d$ linearly independent directions (where $d$ is the dimension of the rate vector) to form a basis. Let these indices be $l_1, \dots, l_d$.

    \item \textbf{Permutation Search:} Since the eigenvalues in $\bm{D}_l$ are arbitrarily ordered for each $l$, we must determine the correct correspondence between directions. We fix the ordering for the first direction $l_1$. For the remaining $d-1$ basis directions, we iterate through all possible $r!$ permutations (where $r$ is the rank/number of components).
    
    For each permutation hypothesis, we construct a candidate frequency vector $\hat{\bm{\omega}}$ by solving the linear system defined by the basis directions.

    \item \textbf{Validation:} We validate each candidate $\hat{\bm{\omega}}$ against the remaining $M-d$ directions. We compute the predicted phase shifts $\delta \bm{u}_l^\top \hat{\bm{\omega}}$ and compare them with the observed eigenvalues of $\bm{\Psi}_l$ (under the best matching permutation for that direction). The hypothesis that minimizes the total angular error across all directions is selected.

    \item \textbf{Final Estimation:} Once the correct permutations are determined for all directions, we form the "unwrapped" phase matrix and solve for $\bm{\omega}$ using the full set of $M$ directions via least squares.
\end{enumerate}

\subsection{Results}
The implementation of this matching strategy yielded a dramatic improvement in estimation accuracy. In the test case where the original algorithm produced a rate error of approximately 11.11, the improved algorithm achieved a rate error of \textbf{0.89}. The weight error decreased from 0.12 to \textbf{0.005}. Crucially, the "mass stealing" effect was completely eliminated, with the algorithm correctly identifying the distinct components.

This approach is computationally feasible for small to moderate $r$ (since the complexity scales with $(r!)^{d-1}$), which covers most practical applications of this method.

\subsection{Alternative Approach: Global Subspace Estimation}
An alternative method was also investigated to address the basis mismatch issue. The hypothesis was that estimating a single \textit{global} signal subspace from all data slices simultaneously would force the Rotational Invariance Matrices to share a common basis, thereby enabling the use of standard joint diagonalization.

This "Global SVD" approach involves:
\begin{enumerate}
    \item Stacking all measurement matrices $\bm{Z}_l$ (for $l=1,\dots,M$) into a single large matrix $\bm{X}_{\text{glob}}$ of size $(M \cdot N) \times S$.
    \item Performing a single SVD on $\bm{X}_{\text{glob}}$ to extract a global signal subspace $\bm{U}_{\text{glob}}$ of dimension $r$.
    \item Extracting the direction-specific subspaces $\bm{U}_l$ as blocks of $\bm{U}_{\text{glob}}$ and computing $\bm{\Psi}_l$ within this common framework.
\end{enumerate}

However, experimental validation showed that this method performed significantly worse than the Brute-Force Eigenvalue Matching (Rate Error $\approx 30.7$ vs $0.89$). The failure is attributed to the fact that the true signal subspaces for different directions are nearly orthogonal (as confirmed by subspace distance metrics). Stacking them results in a high-rank matrix where a rank-$r$ truncation discards significant information, leading to a poor approximation of the underlying signal structure. This confirms that preserving the independence of the directional subspaces is crucial for accurate estimation.
