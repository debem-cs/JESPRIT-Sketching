\section{Algorithm Improvements and Stability Analysis}

\subsection{Issue Identification: Component Mixing and Basis Mismatch}
During the evaluation of the JESPRIT algorithm, a significant issue was observed where the estimated rates ($\bm{\lambda}$) exhibited "mass stealing" between components. For example, in a scenario with true rates of 100 and 100, the algorithm would consistently estimate approximately 75 and 126. This systematic error persisted even with a large number of samples, indicating a bias rather than variance.

The root cause was identified in the Joint Diagonalization step. The standard JESPRIT formulation employs a joint diagonalization algorithm (typically based on Jacobi rotations) that explicitly searches for a unitary matrix $\bm{V}$ (i.e., $\bm{V}\bm{V}^H = \bm{I}$) to simultaneously diagonalize the set of Rotational Invariance Matrices $\bm{\Psi}_l$.

However, in the general case of mixed Poisson estimation, especially when the steering vectors are not orthogonal or the components are correlated, the true diagonalizing matrix $\bm{T}$ (which relates the signal subspace to the canonical basis) is not necessarily unitary. Since the standard algorithm is constrained to the manifold of unitary matrices, it cannot recover the correct non-unitary transformation $\bm{T}$. Instead, it finds the "closest" unitary approximation, which results in a compromised solution that effectively "mixes" the components, leading to the observed bias and "mass stealing".

\subsection{Proposed Solution: Brute-Force Eigenvalue Matching}
To resolve this, we replaced the joint diagonalization approach with a Brute-Force Eigenvalue Matching strategy. This method acknowledges that while the eigenvectors may differ across directions, the eigenvalues (which contain the frequency information) are intrinsic to the underlying components.

The improved algorithm proceeds as follows:

\begin{enumerate}
    \item \textbf{Independent Diagonalization:} Instead of attempting to find a common basis, we compute the eigendecomposition of each $\bm{\Psi}_l$ independently:
    \[
    \bm{\Psi}_l = \bm{V}_l \bm{D}_l \bm{V}_l^{-1}
    \]
    where $\bm{D}_l$ is a diagonal matrix containing the eigenvalues $\mu_{l,k} = \exp(j \delta \bm{u}_l^\top \bm{\omega}_k)$. This avoids the error introduced by enforcing a common basis.

    \item \textbf{Basis Selection:} We select a subset of $d$ linearly independent directions (where $d$ is the dimension of the rate vector) to form a basis. Let these indices be $l_1, \dots, l_d$.

    \item \textbf{Permutation Search:} Since the eigenvalues in $\bm{D}_l$ are arbitrarily ordered for each $l$, we must determine the correct correspondence between directions. We fix the ordering for the first direction $l_1$. For the remaining $d-1$ basis directions, we iterate through all possible $r!$ permutations (where $r$ is the rank/number of components).
    
    For each permutation hypothesis, we construct a candidate frequency vector $\hat{\bm{\omega}}$ by solving the linear system defined by the basis directions.

    \item \textbf{Validation:} We validate each candidate $\hat{\bm{\omega}}$ against the remaining $M-d$ directions. We compute the predicted phase shifts $\delta \bm{u}_l^\top \hat{\bm{\omega}}$ and compare them with the observed eigenvalues of $\bm{\Psi}_l$ (under the best matching permutation for that direction). The hypothesis that minimizes the total angular error across all directions is selected.

    \item \textbf{Final Estimation:} Once the correct permutations are determined for all directions, we form the "unwrapped" phase matrix and solve for $\bm{\omega}$ using the full set of $M$ directions via least squares.
\end{enumerate}

\subsection{Results}
The implementation of this matching strategy yielded a dramatic improvement in estimation accuracy. In the test case where the original algorithm produced a rate error of approximately 11.11, the improved algorithm achieved a rate error of \textbf{0.89}. The weight error decreased from 0.12 to \textbf{0.005}. Crucially, the "mass stealing" effect was completely eliminated, with the algorithm correctly identifying the distinct components.

This approach is computationally feasible for small to moderate $r$ (since the complexity scales with $(r!)^{d-1}$), which covers most practical applications of this method.
