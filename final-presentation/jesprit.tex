\section{JESPRIT for Parameters Estimation of Mixed Poisson distribution}

\begin{frame}
    \sectionpage
\end{frame}

\begin{frame}{Problem Formulation: Mixed Poisson Recovery}
    \textbf{Goal:} Recover latent parameters of a Mixed Poisson distribution from count data.
    \begin{itemize}
        \item \textbf{Model:} $X \sim \sum_{k=1}^r \pi_k \text{Pois}(\bm{\lambda}_k)$
        \item \textbf{Unknowns:} Rate matrix $\mathbf{A} = [\bm{\lambda}_1, \dots, \bm{\lambda}_r]$ and weights $\bm{\pi}$.
    \end{itemize}
    

    
    \vspace{0.2cm}
    \textbf{Sketching Approach:}
    \begin{enumerate}
        \item Compute \textbf{Empirical PGF} at specific points: $\mathbf{t}(\mathbf{u}, n) = \mathbf{1} + j \Delta n \mathbf{u}$.
        \item Map samples to theoretical expression for the PGF of the Mixed Poisson.
        \item Apply \textbf{JESPRIT} to recover parameters.
    \end{enumerate}
\end{frame}

\begin{frame}{Sampling Strategy: The Empirical PGF}
    \textbf{Why Empirical PGF?}
    \begin{itemize}
        \item We lack the true distribution, but we have samples $\mathbf{x}^{(j)}$.
        \item PGF form: $\hat{G}_{\mathbf{X}}(\mathbf{t}) = \frac{1}{N_s} \sum_{j=1}^{N_s} e^{\langle \mathbf{x}^{(j)}, \ln(\mathbf{t}) \rangle}$.
    \end{itemize}

    \vspace{0.4cm}
    \textbf{Line Sampling for Shift Invariance}
    \begin{itemize}
        \item Single points are not enough. We need a \textbf{sequence} to capture the rotation invariance.
        \item For each direction vector $\mathbf{u}_l$, we sample along a line in the complex domain:
    \end{itemize}
    \begin{equation*}
        \mathbf{t}(\mathbf{u}_l, n) = \mathbf{1} + j \Delta n \mathbf{u}_l, \quad n = 0, 1, \dots, 2N-1
    \end{equation*}
\end{frame}

\begin{frame}{The JESPRIT Algorithm}
    \textbf{Key Innovation: Global Subspace Estimation}
    \begin{itemize}
        \item Instead of processing each direction independently, we \textbf{stack} directional samples matrices $Z_l$ from all directions into $\mathbf{X}_{\text{glob}}$.
        \item \textbf{Global SVD:} $\mathbf{X}_{\text{glob}} \approx \mathbf{U}_{\text{glob}} \mathbf{\Sigma} \mathbf{V}^H$.
        \item Ensures all directional subspaces $\hat{\mathbf{U}}_l$ share a \textbf{coherent basis}.
    \end{itemize}

    \vspace{0.3cm}
    \textbf{Recovery Steps:}
    \small
    \begin{enumerate}
        \item \textbf{RIMs:} Solve $\hat{\mathbf{U}}_{l, \uparrow} \Psi_l \approx \hat{\mathbf{U}}_{l, \downarrow}$ for shifts.
        \item \textbf{Joint Diagonalization:} Find $\mathbf{T}$ such that for all $l$:
        $$ \Psi_l \approx \mathbf{T} \Phi_l \mathbf{T}^{-1}, \quad \Phi_l = \text{diag}(\phi_{1,l}, \dots, \phi_{r,l}) $$
        \item \textbf{Extraction:} Eigenvalues $\phi_{k,l}$ give Rates $\bm{\lambda}_k$ via:
        $$ \phi_{k,l} = e^{j \Delta \langle \bm{\lambda}_k, \mathbf{u}_l \rangle} $$
        \item \textbf{Probabilities ($\bm{\pi}$):} Solve linear system $\mathbf{y} \approx \mathbf{E} \bm{\pi}$ via Least Squares:
        $$ \min_{\bm{\pi}} \| \mathbf{y} - \mathbf{E} \bm{\pi} \|_2^2 \quad \text{where } E_{l,k} = e^{j \Delta \langle \hat{\bm{\lambda}}_k, \mathbf{u}_l \rangle} $$
    \end{enumerate}
\end{frame}

\begin{frame}{Results: Parameter Analysis \& Phase Unwrapping}
    \begin{columns}
        \column{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth,height=0.5\textheight,keepaspectratio]{imgs/evaluate_parameters_without_unwrapping.png}
        \captionof{figure}{Error without Unwrapping}
        
        \column{0.5\textwidth}
        \small
        \textbf{1. Phase Unwrapping:}
        \begin{itemize}
            \item Unwrapping \textit{increases} error here.
            \item Optimal scale: $\Delta \approx 1/\max(A)$.
        \end{itemize}

        \vspace{0.2cm}
        \textbf{2. Parameter Sensitivity:}
        \begin{itemize}
            \item \textbf{Directions ($M$) \& Snapshots ($S$):} Robust to over-sampling.
            \item \textbf{Samples ($N$):} Sensitive. Large $N$ causes aliasing/wrapping issues.
        \end{itemize}
    \end{columns}
\end{frame}

\begin{frame}{Results: Sample Complexity}
    \begin{columns}
        \column{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth,height=0.5\textheight,keepaspectratio]{imgs/sample_complexity_0_to_10000.png}
        \captionof{figure}{Success Rate (Large Range)}
        
        \column{0.5\textwidth}
        \small
        \textbf{Experiment Setup:}
        \begin{itemize}
            \item A = random(range, d, r).
            \item Increase number of samples until MRE $< 10\%$.
            \item Increase dimension $r$ while success rate $>75\%$.
        \end{itemize}

        \textbf{Finding 2: Dynamic Range}
        \begin{itemize}
            \item A larger rate range in $A$ improves recovery.
        \end{itemize}
        
        \vspace{0.2cm}
        \textbf{Scalability:}
        \begin{itemize}
            \item Algorithm performance depends on Rank $r$, not Dimension $d$.
        \end{itemize}
    \end{columns}
\end{frame}

